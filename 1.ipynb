{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Carriage Crowd Detection using YOLO + ZIP-EBC\n",
        "\n",
        "## Complete Implementation for Counting People Including Occluded Persons\n",
        "\n",
        "This notebook implements an intelligent crowd counting system that combines:\n",
        "- **YOLO**: For detecting visible persons\n",
        "- **ZIP-EBC**: For estimating occluded persons using density maps\n",
        "- **ROI Spatial Fusion**: For combining both methods adaptively\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Section 1: Installation and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics opencv-python pillow numpy scipy matplotlib torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Tuple, List, Dict\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All packages imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Section 2: Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "    \"\"\"Configuration parameters for the detection system\"\"\"\n",
        "    \n",
        "    # YOLO Configuration\n",
        "    YOLO_MODEL = 'yolov8n.pt'  # Options: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt\n",
        "    YOLO_CONF_THRESHOLD = 0.25  # Confidence threshold for YOLO detection\n",
        "    YOLO_IOU_THRESHOLD = 0.45   # IoU threshold for NMS\n",
        "    \n",
        "    # Density Estimation Configuration\n",
        "    LOW_DENSITY_THRESHOLD = 5   # If YOLO detects fewer than this, use YOLO only\n",
        "    HIGH_CONFIDENCE_THRESHOLD = 0.6  # Average confidence threshold\n",
        "    \n",
        "    # ZIP-EBC (Density Map) Configuration\n",
        "    DENSITY_SIGMA = 15  # Gaussian kernel sigma for density map\n",
        "    DENSITY_THRESHOLD = 0.1  # Threshold for valid density regions\n",
        "    \n",
        "    # Spatial Fusion Parameters\n",
        "    FUSION_WEIGHT_YOLO = 0.6\n",
        "    FUSION_WEIGHT_DENSITY = 0.4\n",
        "    \n",
        "    # Image Configuration\n",
        "    IMAGE_FILE = 'train.jpeg'  # Input image filename\n",
        "    \n",
        "    # Visualization\n",
        "    SHOW_DETECTIONS = True\n",
        "    SAVE_RESULTS = True\n",
        "    OUTPUT_DIR = 'output'\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded!\")\n",
        "print(f\"üì∏ Input image: {config.IMAGE_FILE}\")\n",
        "print(f\"üìÅ Output directory: {config.OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üó∫Ô∏è Section 3: Density Map Generation (ZIP-EBC Implementation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DensityMapEstimator:\n",
        "    \"\"\"\n",
        "    ZIP-EBC (Zero-Inflated Poisson - Empirical Bayesian Counting)\n",
        "    Generates density maps to estimate occluded persons\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, sigma=15):\n",
        "        self.sigma = sigma\n",
        "    \n",
        "    def generate_gaussian_kernel(self, height, width, center_x, center_y, sigma):\n",
        "        \"\"\"Generate a 2D Gaussian kernel centered at (center_x, center_y)\"\"\"\n",
        "        x = np.arange(0, width, 1, float)\n",
        "        y = np.arange(0, height, 1, float)\n",
        "        y = y[:, np.newaxis]\n",
        "        \n",
        "        x0 = center_x\n",
        "        y0 = center_y\n",
        "        \n",
        "        return np.exp(-((x - x0)**2 + (y - y0)**2) / (2 * sigma**2))\n",
        "    \n",
        "    def create_density_map(self, image_shape, detections):\n",
        "        \"\"\"\n",
        "        Create density map from YOLO detections\n",
        "        \n",
        "        Args:\n",
        "            image_shape: (height, width, channels)\n",
        "            detections: List of detection boxes [x1, y1, x2, y2, conf, class]\n",
        "        \n",
        "        Returns:\n",
        "            density_map: 2D array representing person density\n",
        "        \"\"\"\n",
        "        height, width = image_shape[:2]\n",
        "        density_map = np.zeros((height, width), dtype=np.float32)\n",
        "        \n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2 = map(int, det[:4])\n",
        "            center_x = (x1 + x2) // 2\n",
        "            center_y = (y1 + y2) // 2\n",
        "            \n",
        "            # Generate Gaussian blob at person center\n",
        "            gaussian = self.generate_gaussian_kernel(height, width, center_x, center_y, self.sigma)\n",
        "            density_map += gaussian\n",
        "        \n",
        "        # Apply Gaussian smoothing for better density estimation\n",
        "        density_map = gaussian_filter(density_map, sigma=self.sigma/2)\n",
        "        \n",
        "        return density_map\n",
        "    \n",
        "    def estimate_from_density(self, density_map, roi_mask=None):\n",
        "        \"\"\"\n",
        "        Estimate count from density map using ZIP-EBC principle\n",
        "        \n",
        "        Args:\n",
        "            density_map: 2D density map\n",
        "            roi_mask: Optional binary mask for region of interest\n",
        "        \n",
        "        Returns:\n",
        "            estimated_count: Estimated number of people\n",
        "        \"\"\"\n",
        "        if roi_mask is not None:\n",
        "            density_map = density_map * roi_mask\n",
        "        \n",
        "        # Integrate density over the region\n",
        "        total_density = np.sum(density_map)\n",
        "        \n",
        "        # Convert density to count estimation\n",
        "        # Assuming each person contributes approximately 1.0 to the density\n",
        "        estimated_count = total_density / (2 * np.pi * self.sigma**2)\n",
        "        \n",
        "        return int(np.round(estimated_count))\n",
        "\n",
        "print(\"‚úÖ DensityMapEstimator class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Section 4: YOLO Detection Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YOLODetector:\n",
        "    \"\"\"Wrapper for YOLO person detection\"\"\"\n",
        "    \n",
        "    def __init__(self, model_path='yolov8n.pt', conf_threshold=0.25, iou_threshold=0.45):\n",
        "        print(f\"Loading YOLO model: {model_path}...\")\n",
        "        self.model = YOLO(model_path)\n",
        "        self.conf_threshold = conf_threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.person_class_id = 0  # COCO dataset person class\n",
        "        print(\"‚úÖ YOLO model loaded successfully!\")\n",
        "    \n",
        "    def detect(self, image):\n",
        "        \"\"\"\n",
        "        Detect persons in image\n",
        "        \n",
        "        Args:\n",
        "            image: numpy array (BGR format)\n",
        "        \n",
        "        Returns:\n",
        "            detections: List of [x1, y1, x2, y2, confidence, class_id]\n",
        "            results: Raw YOLO results object\n",
        "        \"\"\"\n",
        "        results = self.model(image, conf=self.conf_threshold, iou=self.iou_threshold, verbose=False)\n",
        "        \n",
        "        detections = []\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "                # Filter only person class\n",
        "                if int(box.cls[0]) == self.person_class_id:\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                    conf = float(box.conf[0])\n",
        "                    detections.append([x1, y1, x2, y2, conf, self.person_class_id])\n",
        "        \n",
        "        return detections, results[0]\n",
        "    \n",
        "    def get_average_confidence(self, detections):\n",
        "        \"\"\"Calculate average confidence of detections\"\"\"\n",
        "        if len(detections) == 0:\n",
        "            return 0.0\n",
        "        return np.mean([det[4] for det in detections])\n",
        "\n",
        "print(\"‚úÖ YOLODetector class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÄ Section 5: ROI Spatial Fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SpatialFusion:\n",
        "    \"\"\"\n",
        "    Implements ROI Spatial Fusion combining YOLO and Density Estimation\n",
        "    \n",
        "    Formula: C_total = Œ£ I(pos(i) ‚àâ P) + ‚à´‚à´_P M(x,y) dx dy\n",
        "    where:\n",
        "    - D_YOLO is the set of YOLO detections\n",
        "    - P is the polygon/region\n",
        "    - I is an indicator function\n",
        "    - M(x,y) is the masked density map\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, yolo_weight=0.6, density_weight=0.4):\n",
        "        self.yolo_weight = yolo_weight\n",
        "        self.density_weight = density_weight\n",
        "    \n",
        "    def create_roi_mask(self, image_shape, detections, expansion_factor=1.5):\n",
        "        \"\"\"\n",
        "        Create ROI mask for high-density regions\n",
        "        \n",
        "        Args:\n",
        "            image_shape: (height, width)\n",
        "            detections: YOLO detections\n",
        "            expansion_factor: Factor to expand bounding boxes\n",
        "        \n",
        "        Returns:\n",
        "            mask: Binary mask of ROI regions\n",
        "        \"\"\"\n",
        "        height, width = image_shape[:2]\n",
        "        mask = np.zeros((height, width), dtype=np.uint8)\n",
        "        \n",
        "        # Create mask around detected persons (potential occlusion areas)\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2 = map(int, det[:4])\n",
        "            \n",
        "            # Expand box to capture nearby occluded persons\n",
        "            w = x2 - x1\n",
        "            h = y2 - y1\n",
        "            expand_w = int(w * (expansion_factor - 1) / 2)\n",
        "            expand_h = int(h * (expansion_factor - 1) / 2)\n",
        "            \n",
        "            x1_exp = max(0, x1 - expand_w)\n",
        "            y1_exp = max(0, y1 - expand_h)\n",
        "            x2_exp = min(width, x2 + expand_w)\n",
        "            y2_exp = min(height, y2 + expand_h)\n",
        "            \n",
        "            mask[y1_exp:y2_exp, x1_exp:x2_exp] = 1\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def fuse_counts(self, yolo_count, density_count, yolo_confidence):\n",
        "        \"\"\"\n",
        "        Fuse YOLO and density-based counts\n",
        "        \n",
        "        Args:\n",
        "            yolo_count: Count from YOLO\n",
        "            density_count: Count from density estimation\n",
        "            yolo_confidence: Average confidence of YOLO detections\n",
        "        \n",
        "        Returns:\n",
        "            final_count: Fused count\n",
        "        \"\"\"\n",
        "        # Adaptive weighting based on YOLO confidence\n",
        "        adaptive_yolo_weight = self.yolo_weight * yolo_confidence\n",
        "        adaptive_density_weight = self.density_weight * (1 + (1 - yolo_confidence))\n",
        "        \n",
        "        # Normalize weights\n",
        "        total_weight = adaptive_yolo_weight + adaptive_density_weight\n",
        "        adaptive_yolo_weight /= total_weight\n",
        "        adaptive_density_weight /= total_weight\n",
        "        \n",
        "        # Weighted fusion\n",
        "        fused_count = (adaptive_yolo_weight * yolo_count + \n",
        "                      adaptive_density_weight * density_count)\n",
        "        \n",
        "        return int(np.round(fused_count))\n",
        "\n",
        "print(\"‚úÖ SpatialFusion class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Section 6: Main Crowd Counting Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainCrowdCounter:\n",
        "    \"\"\"\n",
        "    Main pipeline for counting people in train carriages\n",
        "    Combines YOLO and ZIP-EBC for robust counting\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.yolo_detector = YOLODetector(\n",
        "            model_path=config.YOLO_MODEL,\n",
        "            conf_threshold=config.YOLO_CONF_THRESHOLD,\n",
        "            iou_threshold=config.YOLO_IOU_THRESHOLD\n",
        "        )\n",
        "        self.density_estimator = DensityMapEstimator(sigma=config.DENSITY_SIGMA)\n",
        "        self.spatial_fusion = SpatialFusion(\n",
        "            yolo_weight=config.FUSION_WEIGHT_YOLO,\n",
        "            density_weight=config.FUSION_WEIGHT_DENSITY\n",
        "        )\n",
        "        \n",
        "        # Create output directory\n",
        "        if config.SAVE_RESULTS:\n",
        "            os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "    \n",
        "    def process_image(self, image_path):\n",
        "        \"\"\"\n",
        "        Process a single image to count people\n",
        "        \n",
        "        Args:\n",
        "            image_path: Path to input image\n",
        "        \n",
        "        Returns:\n",
        "            results: Dictionary containing all results\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        if isinstance(image_path, str):\n",
        "            image = cv2.imread(image_path)\n",
        "        else:\n",
        "            image = image_path\n",
        "        \n",
        "        if image is None:\n",
        "            raise ValueError(f\"Could not load image: {image_path}\")\n",
        "        \n",
        "        # Step 1: YOLO Detection\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Step 1: Running YOLO detection...\")\n",
        "        print(\"=\"*70)\n",
        "        detections, yolo_results = self.yolo_detector.detect(image)\n",
        "        yolo_count = len(detections)\n",
        "        avg_confidence = self.yolo_detector.get_average_confidence(detections)\n",
        "        \n",
        "        print(f\"  ‚úì YOLO detected: {yolo_count} persons\")\n",
        "        print(f\"  ‚úì Average confidence: {avg_confidence:.2%}\")\n",
        "        \n",
        "        # Step 2: Decision - Use YOLO only or apply fusion?\n",
        "        use_fusion = (yolo_count > self.config.LOW_DENSITY_THRESHOLD or \n",
        "                     avg_confidence < self.config.HIGH_CONFIDENCE_THRESHOLD)\n",
        "        \n",
        "        if not use_fusion:\n",
        "            print(\"\\n  ‚ÑπÔ∏è  High confidence & low density -> Using YOLO count only\")\n",
        "            final_count = yolo_count\n",
        "            density_count = 0\n",
        "            density_map = None\n",
        "        else:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"Step 2: Applying ROI Spatial Fusion (YOLO + ZIP-EBC)...\")\n",
        "            print(\"=\"*70)\n",
        "            \n",
        "            # Generate density map\n",
        "            density_map = self.density_estimator.create_density_map(\n",
        "                image.shape, detections\n",
        "            )\n",
        "            \n",
        "            # Create ROI mask for high-density regions\n",
        "            roi_mask = self.spatial_fusion.create_roi_mask(\n",
        "                image.shape, detections, expansion_factor=1.5\n",
        "            )\n",
        "            \n",
        "            # Estimate count from density in ROI\n",
        "            density_count = self.density_estimator.estimate_from_density(\n",
        "                density_map, roi_mask\n",
        "            )\n",
        "            \n",
        "            print(f\"  ‚úì Density estimation: {density_count} persons\")\n",
        "            \n",
        "            # Fuse counts\n",
        "            final_count = self.spatial_fusion.fuse_counts(\n",
        "                yolo_count, density_count, avg_confidence\n",
        "            )\n",
        "            \n",
        "            print(f\"  ‚úì Fused count: {final_count} persons\")\n",
        "        \n",
        "        # Prepare results\n",
        "        results = {\n",
        "            'image': image,\n",
        "            'detections': detections,\n",
        "            'yolo_count': yolo_count,\n",
        "            'density_count': density_count,\n",
        "            'final_count': final_count,\n",
        "            'avg_confidence': avg_confidence,\n",
        "            'density_map': density_map,\n",
        "            'used_fusion': use_fusion\n",
        "        }\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def visualize_results(self, results, save_path=None):\n",
        "        \"\"\"\n",
        "        Visualize detection results\n",
        "        \n",
        "        Args:\n",
        "            results: Results dictionary from process_image\n",
        "            save_path: Optional path to save visualization\n",
        "        \"\"\"\n",
        "        image = results['image'].copy()\n",
        "        detections = results['detections']\n",
        "        density_map = results['density_map']\n",
        "        \n",
        "        # Create figure with subplots\n",
        "        if density_map is not None:\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "        else:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "            axes = [axes[0], axes[1], None]\n",
        "        \n",
        "        # Plot 1: Original image with YOLO detections\n",
        "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2, conf = det[:5]\n",
        "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "            cv2.putText(img_rgb, f'{conf:.2f}', (x1, y1-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "        \n",
        "        axes[0].imshow(img_rgb)\n",
        "        axes[0].set_title(f'YOLO Detections: {results[\"yolo_count\"]} persons\\n'\n",
        "                         f'Avg Confidence: {results[\"avg_confidence\"]:.2%}', \n",
        "                         fontsize=14, weight='bold')\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Plot 2: Detection summary\n",
        "        axes[1].text(0.5, 0.75, f'YOLO Count: {results[\"yolo_count\"]}',\n",
        "                    ha='center', va='center', fontsize=18, weight='bold')\n",
        "        \n",
        "        if results['used_fusion']:\n",
        "            axes[1].text(0.5, 0.55, f'Density Count: {results[\"density_count\"]}',\n",
        "                        ha='center', va='center', fontsize=18, weight='bold')\n",
        "            axes[1].text(0.5, 0.3, f'üéØ FINAL COUNT: {results[\"final_count\"]}',\n",
        "                        ha='center', va='center', fontsize=24, weight='bold',\n",
        "                        color='red')\n",
        "            axes[1].text(0.5, 0.1, '(Using ROI Spatial Fusion)',\n",
        "                        ha='center', va='center', fontsize=13, style='italic')\n",
        "        else:\n",
        "            axes[1].text(0.5, 0.3, f'üéØ FINAL COUNT: {results[\"final_count\"]}',\n",
        "                        ha='center', va='center', fontsize=24, weight='bold',\n",
        "                        color='green')\n",
        "            axes[1].text(0.5, 0.1, '(YOLO Only - High Confidence)',\n",
        "                        ha='center', va='center', fontsize=13, style='italic')\n",
        "        \n",
        "        axes[1].set_xlim(0, 1)\n",
        "        axes[1].set_ylim(0, 1)\n",
        "        axes[1].axis('off')\n",
        "        axes[1].set_facecolor('#f0f0f0')\n",
        "        \n",
        "        # Plot 3: Density map (if available)\n",
        "        if density_map is not None and axes[2] is not None:\n",
        "            im = axes[2].imshow(density_map, cmap='hot', interpolation='bilinear')\n",
        "            axes[2].set_title('Density Map (ZIP-EBC)', fontsize=14, weight='bold')\n",
        "            axes[2].axis('off')\n",
        "            plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        \n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "            print(f\"\\nüìÅ Visualization saved to: {save_path}\")\n",
        "        \n",
        "        plt.show()\n",
        "        \n",
        "        return fig\n",
        "\n",
        "print(\"‚úÖ TrainCrowdCounter class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé¨ Section 7: Initialize System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üöÜ Train Carriage Crowd Detection - YOLO + ZIP-EBC\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize counter\n",
        "counter = TrainCrowdCounter(config)\n",
        "\n",
        "print(\"\\n‚úÖ System initialized successfully!\")\n",
        "print(f\"üìä Ready to process: {config.IMAGE_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì∏ Section 8: Process Train Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if image exists\n",
        "if not os.path.exists(config.IMAGE_FILE):\n",
        "    print(f\"‚ö†Ô∏è  Warning: {config.IMAGE_FILE} not found!\")\n",
        "    print(\"Please upload your train carriage image and name it 'train.jpeg'\")\n",
        "    print(\"Or change the IMAGE_FILE in the Config class to your image filename.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Found image: {config.IMAGE_FILE}\")\n",
        "    \n",
        "    # Load and display original image\n",
        "    original_img = cv2.imread(config.IMAGE_FILE)\n",
        "    img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title('Original Train Carriage Image', fontsize=16, weight='bold')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"üìè Image size: {original_img.shape[1]}x{original_img.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Section 9: Run Detection & Count People"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process the image\n",
        "if os.path.exists(config.IMAGE_FILE):\n",
        "    results = counter.process_image(config.IMAGE_FILE)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ DETECTION COMPLETE!\")\n",
        "    print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Section 10: Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results\n",
        "if os.path.exists(config.IMAGE_FILE):\n",
        "    save_path = os.path.join(config.OUTPUT_DIR, 'detection_result.jpg')\n",
        "    counter.visualize_results(results, save_path=save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Section 11: Detailed Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print detailed summary\n",
        "if os.path.exists(config.IMAGE_FILE):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìã DETECTION SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nüéØ YOLO Detection Results:\")\n",
        "    print(f\"   ‚Ä¢ Persons detected: {results['yolo_count']}\")\n",
        "    print(f\"   ‚Ä¢ Average confidence: {results['avg_confidence']:.2%}\")\n",
        "    print(f\"   ‚Ä¢ Total detections: {len(results['detections'])}\")\n",
        "    \n",
        "    if results['used_fusion']:\n",
        "        print(f\"\\nüó∫Ô∏è  ZIP-EBC Density Estimation:\")\n",
        "        print(f\"   ‚Ä¢ Estimated count: {results['density_count']} persons\")\n",
        "        print(f\"   ‚Ä¢ Method: ROI Spatial Fusion\")\n",
        "        print(f\"   ‚Ä¢ Fusion weights: YOLO={config.FUSION_WEIGHT_YOLO}, Density={config.FUSION_WEIGHT_DENSITY}\")\n",
        "    else:\n",
        "        print(f\"\\n‚úì Using YOLO only (High confidence detection)\")\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üéØ FINAL COUNT: {results['final_count']} PERSONS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # Detection confidence distribution\n",
        "    if len(results['detections']) > 0:\n",
        "        confidences = [det[4] for det in results['detections']]\n",
        "        \n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.hist(confidences, bins=10, color='skyblue', edgecolor='black')\n",
        "        plt.xlabel('Confidence Score', fontsize=12)\n",
        "        plt.ylabel('Number of Detections', fontsize=12)\n",
        "        plt.title('Detection Confidence Distribution', fontsize=14, weight='bold')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.subplot(1, 2, 2)\n",
        "        labels = ['YOLO\\nCount', 'Density\\nCount', 'Final\\nCount']\n",
        "        counts = [results['yolo_count'], results['density_count'], results['final_count']]\n",
        "        colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
        "        bars = plt.bar(labels, counts, color=colors, edgecolor='black', linewidth=2)\n",
        "        plt.ylabel('Person Count', fontsize=12)\n",
        "        plt.title('Count Comparison', fontsize=14, weight='bold')\n",
        "        plt.grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{int(height)}',\n",
        "                    ha='center', va='bottom', fontsize=14, weight='bold')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(config.OUTPUT_DIR, 'statistics.jpg'), dpi=150)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Section 12: Save Results to JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to JSON\n",
        "if os.path.exists(config.IMAGE_FILE):\n",
        "    results_json = {\n",
        "        'image_file': config.IMAGE_FILE,\n",
        "        'yolo_count': results['yolo_count'],\n",
        "        'density_count': results['density_count'],\n",
        "        'final_count': results['final_count'],\n",
        "        'avg_confidence': float(results['avg_confidence']),\n",
        "        'used_fusion': results['used_fusion'],\n",
        "        'detections': [\n",
        "            {\n",
        "                'bbox': [float(x) for x in det[:4]],\n",
        "                'confidence': float(det[4])\n",
        "            } for det in results['detections']\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    json_path = os.path.join(config.OUTPUT_DIR, 'results.json')\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(results_json, f, indent=2)\n",
        "    \n",
        "    print(f\"‚úÖ Results saved to: {json_path}\")\n",
        "    print(\"\\nJSON Content:\")\n",
        "    print(json.dumps(results_json, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé• Section 13: Bonus - Video Processing (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to process video\n",
        "\"\"\"\n",
        "def process_video(video_path, output_path=None, sample_rate=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    \n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Could not open video: {video_path}\")\n",
        "    \n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    \n",
        "    print(f\"Video: {width}x{height} @ {fps}fps, {total_frames} frames\")\n",
        "    \n",
        "    if output_path:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "    \n",
        "    frame_results = []\n",
        "    frame_idx = 0\n",
        "    \n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        if frame_idx % sample_rate == 0:\n",
        "            print(f\"Processing frame {frame_idx}/{total_frames}...\")\n",
        "            \n",
        "            try:\n",
        "                result = counter.process_image(frame)\n",
        "                frame_results.append(result)\n",
        "                \n",
        "                # Draw count on frame\n",
        "                cv2.putText(frame, f'Count: {result[\"final_count\"]}',\n",
        "                          (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5,\n",
        "                          (0, 255, 0), 3)\n",
        "                \n",
        "                for det in result['detections']:\n",
        "                    x1, y1, x2, y2 = map(int, det[:4])\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            \n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\")\n",
        "        \n",
        "        if output_path:\n",
        "            out.write(frame)\n",
        "        \n",
        "        frame_idx += 1\n",
        "    \n",
        "    cap.release()\n",
        "    if output_path:\n",
        "        out.release()\n",
        "        print(f\"Output saved: {output_path}\")\n",
        "    \n",
        "    return frame_results\n",
        "\n",
        "# Example usage:\n",
        "# video_results = process_video('train_video.mp4', 'output_video.mp4', sample_rate=30)\n",
        "\"\"\"\n",
        "\n",
        "print(\"Video processing function defined (commented out)\")\n",
        "print(\"Uncomment and run to process videos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìö Documentation & Usage Guide\n",
        "\n",
        "### How It Works:\n",
        "\n",
        "1. **YOLO Detection**: Detects visible persons with bounding boxes\n",
        "2. **Decision Logic**: \n",
        "   - If low density + high confidence ‚Üí Use YOLO only\n",
        "   - If high density OR low confidence ‚Üí Apply fusion\n",
        "3. **ZIP-EBC Density Estimation**: Creates density map for occluded persons\n",
        "4. **ROI Spatial Fusion**: Combines both methods using weighted fusion\n",
        "\n",
        "### Formula:\n",
        "```\n",
        "C_total = Œ£ I(pos(i) ‚àâ P) + ‚à´‚à´_P M(x,y) dx dy\n",
        "```\n",
        "\n",
        "### Configuration Options:\n",
        "- `YOLO_MODEL`: Choose model size (n/s/m/l/x)\n",
        "- `YOLO_CONF_THRESHOLD`: Detection confidence (0-1)\n",
        "- `DENSITY_SIGMA`: Gaussian kernel size for density map\n",
        "- `FUSION_WEIGHT_YOLO/DENSITY`: Fusion weights\n",
        "\n",
        "### Output Files:\n",
        "- `output/detection_result.jpg`: Visualization with all detections\n",
        "- `output/statistics.jpg`: Confidence distribution and count comparison\n",
        "- `output/results.json`: Detailed results in JSON format\n",
        "\n",
        "### Requirements:\n",
        "- Place your train image as `train.jpeg` in the same directory\n",
        "- Or change `config.IMAGE_FILE` to your image filename\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Completed!\n",
        "\n",
        "Your train carriage crowd detection system is ready! üöÜ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}